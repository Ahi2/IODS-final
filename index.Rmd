---
title: "IODS-final"
author: "Mohamadali Ahi; mohamadali.ahi@helsinki.fi"
date: "15 December 2017"
output:
  html_document:
    df_print: paged
    theme: cosmo
    toc: true
    toc_depth: 2
    fig_caption: true
    fig_width: 6
    fig_height: 4
    code_folding: hide
---

# Abstract
In this report, I set out to understand the effect of Gross National Income per capita in  a given country on its population life expactancy. GNI per capita is a established measure to assess the standard of living in a given country; therefore, it should positively affect the life expectancy of the people in the country. To test my hypothesis, I use linear regression method, and the data from Human Development report gathered by the United Nations. The results show that there is a positive and strong relationship between GNI per capita and life expectancy. 
In addition, I set out to understand whether variables in the Human Development Report can explain different classes of income, measured by GNI per capita. To do so, I divide GNI per capita into four different categories: low, medium low, medium high, and high. The results reveal that these variables can explain the country income. Finally, I dicuss my findings in more depth.  

# Hypotheses, Analysis, and Variables
I intend to know the effect of a given country's income on life expectancy of its population. I expect that people in wealthier countries have naturally a higher life expectancy, as they have higher standard of living, hence healthier and longer life. Accordingly, the following hypothesis is developed:

   H. The wealthier the country, the higher the life expectancy of its population.

In order to test the hypothesis, I use the Human Development dataset, developed by the United Nations, created to stress that people and their capaibilities are the ultimate criteria to evaluate the development of a country, not economic growth alone. 

The data have several indecies. I am interested in two of them for the purpose of this report: Human Development Index and Gender Inequality Index. The former consists of variables such as life expectancy at birth and GNI per capita,  representing long and healthy living and standard of living, respectively. The other index, Gender inequality, as the name implies, looks at the equality between female and male in terms of education, labor participation, and health. It includes variables such as Maternal mortality ratio and Adolescent birth rate.  

To perform my analysis and test the hypothesis, I need to combine these two datasets. Then, I use life expectancy at birth (Life.Exp) as the target variable, representing life expectancy. I use GNI per capita as the predictor, representing population wealth in a given country. Due to the nature of the analysis, I need to run a linear regression. 

In addition, I intend to explore whether different categories of GNI per capita can be explained by other variables in my data. Therefore, I need to perform a Linear Discriminant Analysis (LDA), which is a method to classify the data. 

Overall, when combining the two datasets, the following are the variables:

"Country" = Country name 
"GNI" = Gross National Income per capita 

"Life.Exp" = Life expectancy at birth 

"Edu.Exp" = Expected years of schooling  

"Mat.Mor" = Maternal mortality ratio 

"Ado.Birth" = Adolescent birth rate

"Parli.F" = Percentange of female representatives in parliament

"Edu2.F" = Proportion of females with at least secondary education

"Edu2.M" = Proportion of males with at least secondary education

"Labo.F" = Proportion of females in the labour force

"Labo.M" " Proportion of males in the labour force

"Edu2.FM" = Edu2.F / Edu2.M

"Labo.FM" = Labo2.F / Labo2.M

Observations with missing values have been removed from the dataset in the data wrangling process. 

# Reading the data into R
The human dataset has been prepared [here](https://github.com/Ahi2/IODS-final/blob/master/create_human2.R), using data wrangling procedure as explained in the link.
However, to make sure I am using the correct dataset, I read the data wihch is available online. I call it 'human2'. Then, I look at the structure, dimensions, and a summary of the dataset.

```{r}
human2 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human2.txt", sep  =",", header = T)

str(human2)
dim(human2)
summary(human2)
```

As can be seen the data has 155 observations and 8 variables. In addition, the minimum, mean, median, and maximum values of each variable can also be seen. Now, let us access the libraries we need for the analyses. 

```{r}
library(tidyr)

library(dplyr)

library(ggplot2)

library(GGally)

library(corrplot)

library(MASS)
```

The first analysis is a multiple linear regression. I go through the regression step-by-step, explaining each step as I run the analysis. Then, I perform the Linear Discriminant Analysis in the second part of the report. 

# 1. Multiple Linear Regression 
I first draw a plot to show the distribution of each variable in the dataset as well as the variables correlations. It is always a good idea and sometimes a necessity to know this information before conducting any analysis.

# 1.1 Distributions and correlations of the variables

```{r}
ggpairs(human2)
```

The plot above indicates most variables are not distributed normally. This is usually the case with real data (empirical ones). One way to deal with this is standadzing the variables. Nonetheless, Expected years of schooling (Edu.Exp) and Percetange of female representatives in parliament (Parli.F) seem to have a rather normal distribution.  

Edu.Exp is also postively and strongly correlated with Life.Exp. It also has a positive - but slightly weaker - correlation with GNI per capita. Edu.Exp also has a positive correlation with GNI per capita, too.  

Another interesting but unsurprising correlation is the negative relationship between Maternal mortality (Mat.Mor) and GNI per capita. Mat.Mor has also a negative and strong correlation with Life.Exp, which comes as no surprise. 

Surprisingly, there seems to be a highly weak correlation between GNI per capita and Percentange of female representatives in parliament (Parli.F). This is surprising since one expects that as the standard of living (measured by GDI per capita) increases, the partipcation of females in political arena rises, too. The results do not confirm this.   

The plot below demonstrates these correlations more clearly. The bluish color represents positive correlation. The opposite holds true for the redish color. The higher the correlation, the darker the color. As examples, Mat.Mor is highly and negatively correlated with Edu.Exp and Life.Exp, while it is positively correlated with Adolescent birth rate (Ado.Birth). Life.Exp is positively correlated with Edu2.FM, Edu.Exp, and GNI per capita, and negatively correlated with Mat.Mor and Ado.Birth.

```{r}
cor(human2) %>% corrplot
```

# 1.2 Qplot of the variables in the model
Since I am interested in doing a regression analysis by regressing Life.Exp on GNI (y = Life.Exp and x = GNI), first I draw a qplot of these two variables and fit a regression line. 

```{r}
qplot(GNI, Life.Exp, data = human2) + geom_smooth(method = "lm")
```

It seems that two of the GNI values are outliers, those higher than 75000 dollars a year. Therefore, I remove them to improve the prediction of the model.

```{r}
human2 <- filter(human2, GNI < 75000)
```

Now, I look at the regression line again.
```{r}
qplot(GNI, Life.Exp, data = human2) + geom_smooth(method = "lm")
```

Since I removed the outlier, the regression line seems to better represent the corrlation between GNI and life expectancy. 

# 1.3 Regression model
Now, I run the regression analysis. Then, I interpret the results.

```{r}
my_model <- lm(Life.Exp ~ GNI, data = human2) 
summary(my_model)
```

The results above indicate that GNI is a strong predictor of life expectancy. The P-Value is very marginal. R-square is also high, meaning that the model explains around half of the variance of the target variable, that is, life expectancy.  

Now, I add another predictor to explore whether other variables predict life expectance. To do so, I add Mat.Mor. Therefore, I need to run a multiple linear regression, in which there are more than one predictor of target variable. 

```{r}
my_model2 <- lm(Life.Exp ~ GNI + Mat.Mor, data = human2)
summary(my_model2)
```

As the results indicate, the model is signifcant. The new variable is highly signifcant, too, with a very small P-value. As expected Mat.Mor negatively affects life expectancy. In addition, the R-squated has increased, which is natural as the number of variables increases, R squared also increases. 

# 1.4 Validity of the model
Now, I explore the validity of my model graphically. To do so, I use  the following plots: Residuals vs Fitted values, Normal QQ-plot, and Residuals vs Leverage.

```{r}
par(mfrow = c(2,2))
plot(my_model2, which = c(1,2,5))
```

I first explore "Residuls vs Fitted values". This plot is used to understand the linearity of the model, the unequality of error variance, and to check if there is any outliers. Looking at the plot reveals that the residuals are scattered rather randolmy around 0. It could have been better as now they have not formed a horizontal line perfectly; yet this is acceptable. A horizontal line means that the relationship of the variables in the model is linear and also the errors are equal. There are some values that are far from the rest (lower side of the plot); these could be considered as outliers. How influential they are in our model will be determined by another plot, which I look at now.

The Residuals vs Leverage plot. This plot helps us to understand the influential outliers, those that actually affect our model which are better to be removed. One way to understand those outliers is to look at the Cook's distance lines (dashed red line). If the distance is high, then there are influential outliers. In this plot, some points are far from the Cook's distance line, hence there seem to be influential outlier in the data. In later analysis, these observations should be removed. 

Finally, I explore the Normal Q-Q plot. This plot helps to understand whether the variables are distibuted normally. If points in the plot fall on a straight line, the variables have normal distribution. Most points in the plot fall somewhat on a straight line, hence the normality of the distribution of the variables.

# 2. Linear Discriminant Analysis (LDA)

LDA is a supervised classification method which can be used to model several binery vairbales. LDA is a linear transformation technique used for dimensionality reduction. The independent variables are continuous while the target variables are categorical (binery). 

In this assignment, I am going to use different calsses of GNI as the target variable to  see how other variables explain the classes. 

Because an assumption in LDA is that the variables are normally distributed, it is better to first standardize the data before performing the analysis. To do so, I scale the whole dataset. 

# 2.1 Scaling Dataset  

```{r}
human2_scaled <- scale(human2)
summary(human2_scaled)
```

Now we look at the class of the scaled object, and convert the human2_scaled to a dataframe format.
```{r}
class(human2_scaled)
human2_scaled <- as.data.frame(human2_scaled)
```

# 2.2 Creating a categorical variable from GNI
Because I am interested in different classes of GNI explained by other variables, I now create categorical variables from GNI - which is currently a continous variable. I cut the variable by quantiles to get high, low, and middle rates of GNI per capita. Each quantile indicates the wealth of a country population. For example, high and low indicate wealthy and poor population, respectively.  

First, I look at the summary of GNI.

```{r}
summary(human2_scaled$GNI)
```

Now, I create a quantile vector of GNI and will print it. 

```{r}
bins <- quantile(human2_scaled$GNI)
bins
```

Now, I create the categorical variable, calling it GNI_class. Then, I will look at the table of the new factor GNI_class. 
```{r}
GNI_class <- cut(human2_scaled$GNI, breaks = bins, include.lowest = TRUE, c(label = "low", "med_low", "med_high", "high"))
table(GNI_class)
```

I now remove the original GNI from the dataset
```{r}
human2_scaled <- dplyr::select(human2_scaled, -GNI)
```

Then, I add the new categorical value, GNI_class, to scaled data.
```{r}
human2_scaled <- data.frame(human2_scaled, GNI_class)
```

Now, let us look at the summary of human2_scaled.

```{r}
summary(human2_scaled)
```

# 2.3 Dividing the data into train and test sets
In order to make prediction using a statistical method, it is important to test how well the predictions fit. To do so, one way is to split the data into test and train sets. As the names imply, the training of the model is done by the train set while the prediction is done using the test set. Let us do it. 

First, I look at the number of rows in the dataset, and save the number in 'n'.
```{r}
n <- nrow(human2_scaled)
n
```

I now choose randomly 80% of the rows.
```{r}
ind <- sample(n, size = n * 0.8)
```

Then, I create train set.
```{r}
train <- human2_scaled[ind,]
```

Then, the test set.
```{r}
test <- human2_scaled[-ind,]
```

Now, I take the GNI classes from the test set and save them as 'correct_classes'.
```{r}
correct_classes <- test$GNI_class
```

Then, I remove the GNI_class from the test set.
```{r}
test <- dplyr::select(test, -GNI_class)
```

# 2.4 Performing Linear Disciminant Analysis
We have now created a catergorical variable of GNI, standardized the data, and splitted it into training and test datasets. We are ready to perform LDA. 
I now fit a linear discriminant analysis, using GNI_class as the target variable and all the other variables as predictors. Then, I will print it. 
```{r}
lda.fit <- lda(GNI_class ~ ., data = train)
lda.fit
```

The results above indicate that around 24% of the data belong to low GNI. The respective number for other GNI classes, med_low, med_high, and high are around 25%, 27%, and 23%, respectively. We then have the group means of the variables associated with each class.

We can also see that there are three linear discriminants (LD) becauase we have four taget classes. Proportion of trace shows that LD1 explains the majority of between-group variance (~ 88%).   

Looking at the coefficients of the analysis, we can infer that variables such as 'the ratio of Female and Male populations with secondary education' (Edu2.FM) predicts LD1 very well. The results indicate that the higher the values of this variable, the higher LD1. 

# 2.5 Visualizing LDA

LDA can be visualized with a biplot. There is a biplot arrow function [here](https://stackoverflow.com/questions/17232251/how-can-i-plot-a-biplot-for-lda-in-r), which I use to visualize the LDA.
```{r}
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
```

To continue with plotting, I now create a numeric vector of the train sets crime classes.
```{r}
classes <- as.numeric(train$GNI_class)
```

Now, I plot the lda results. I use lda.arrow function to show the arrows, so the interpretation of the plot will be easier. 
```{r}
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 3)
```

In the above plot, each class has been shown by a distinct color. The plot demonstrates that, for instance, life expectancy (Life.Exp) is a significant variable that positively explains LD1 and also LD2. The ratio of females over males with at least secondary education (Edu2.FM) is also significant but negatively explains LD2, while positively explains LD1. 

# 2.6 Predicting LDA
Now that we have performed LDA, it is time to predict the values based on the model. We already created the test set to be used for predicting the model. The test set is a new dataset here, which can tell us how good the model fits our data. 

I now predict the classes with test data.
```{r}
lda.pred <- predict(lda.fit, newdata = test)
```

Then, I create a table of the correct classes and the predicted ones, running cross tabulation.
```{r}
table(correct = correct_classes, predicted = lda.pred$class)
```

The above results reveal that in most cases the GNI classes have been predicted correctly, particularly in low and high classes. There are some discrepancy in med_low and Med_high, but generally, we can conclude that, based on the data, the model predicts the classes well. Therefore, different classes of GNI - which divides countries into four categories based on their population income and hence standard of living - can be explained by variables in the model such as life expectancy and the ratio of female over male with secondary education.

# Discussion and conclusion
In this report, I worked to understand the effect of GNI on population life expectancy, hypothesizing a positive relationship between the two. I performed a regression analysis to test my hypothesis, which was confirmed. In addition, I explored the effect of maternal mortality ratio on life expectancy, obviously expecting a negative relationship. This was also confirmed. The findings reveal that the higher the standard of living in a country, the higher the population life expectancy. Countries whereby people are wealthier, life expectancy is longer. Examples could be people in north and west Europe or people living in Japan.   
In addition, I intended to understand whether health, knowldge, and empowerment variables explain different categorization of income. In so doing, I divided GNI per capita into four categories. Then, I ran an LDA to explore whether other variables (which were continuous) explain the categories. The model predicted categories well as mentioned in the analysis. This indicates that variables related to, for example, healthy life, knowledge (gained by education), and female participation in society can explain differnces between country income. For instance, countries in which people are more healthy and educated, while females participate more in society enjoy a higher income, hence higher standard of living.  

